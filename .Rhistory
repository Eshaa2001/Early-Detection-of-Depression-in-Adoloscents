####Relation between gender and mdeSI####
#First we will see the distribution of the variable gender
table(da$gender)
#now we will see which gender is suffering from mdeSI the most
mdeSI_yes = subset(da, mdeSI == "Yes")
gender_dist = as.data.frame(table(mdeSI_yes$gender))
colnames(gender_dist) <- c("Gender", "Count") #Renaming the columns
plot_ly(gender_dist, labels = ~Gender, values = ~Count, type = "pie") %>%
layout(title = "Distribution of Gender for mdeSI = Yes")
mdeSI_no = subset(da, mdeSI == "No")
gender_dist2 = as.data.frame(table(mdeSI_no$gender))
colnames(gender_dist2) <- c("Gender", "Count") #Renaming the columns
plot_ly(gender_dist2, labels = ~Gender, values = ~Count, type = "pie") %>%
layout(title = "Distribution of Gender for mdeSI = No")
####Race and mdeSI####
race_mdeSI_counts = table(da$race, da$mdeSI)
# Calculate the percentages of mdeSI = "Yes" for each race
percent_yes = race_mdeSI_counts[, "Yes"] / rowSums(race_mdeSI_counts) * 100
# Create a dataframe with race and percentage of mdeSI = "Yes"
race_percent_yes = data.frame(race = rownames(race_mdeSI_counts), percent_yes = percent_yes)
race = ggplot(race_percent_yes, aes(x = race, y = percent_yes)) +
geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
labs(title = "Percentage of mdeSI = 'Yes' for Each Race",
x = "Race",
y = "Percentage of mdeSI = 'Yes'",
fill = "Race") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplotly(race)
####age and mdeSI####
age_mdeSI_counts = table(da$age, da$mdeSI)
# Calculate the percentages of mdeSI = "Yes" for each race
percent_yes = age_mdeSI_counts[, "Yes"] / rowSums(age_mdeSI_counts) * 100
# Create a dataframe with race and percentage of mdeSI = "Yes"
age_percent_yes = data.frame(age = rownames(age_mdeSI_counts), percent_yes = percent_yes)
age = ggplot(age_percent_yes, aes(x = age, y = percent_yes)) +
geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
labs(title = "Percentage of mdeSI = 'Yes' for Each age group",
x = "age",
y = "Percentage of mdeSI = 'Yes'",
fill = "age") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplotly(age)
####Insurance and mdeSI####
table(da$mdeSI, da$insurance)
#Chi Square test
chi_square_results = data.frame(Column = character(), P_Value = numeric(), row.names = NULL)
columns = c("year", "gender", "age", "race", "insurance", "income",
"fatherInHH", "motherInHH", "siblingU18", "parentInv", "schoolExp")
for (col in columns) {
chi_square_result <- chisq.test(table(da$mdeSI, da[, col]))
p_value <- chi_square_result$p.value
chi_square_results <- rbind(chi_square_results, data.frame(Column = col, P_Value = p_value))
}
View(chi_square_results)
#[Please rename this file as "LastName_FinalProject.R" when you submit it]
library(corrplot)
library(ggplot2)
library(treemap)
library(tidyr)
library(MASS)
library(mixlm)
library(randomForest)
library(RColorBrewer)
library(plotly)
da = read.csv("depression.csv", header = T)
#I have modified the original data to make it more balanced in the target variable
#The proportions of the depressive cases are about the same in the "depression.csv" file
dim(da) #6,000 by 12
str(da)
da$mdeSI = factor(da$mdeSI)
da$income = factor(da$income)
da$gender = factor(da$gender, levels = c("Male", "Female")) #Male is the reference group
da$age = factor(da$age)
da$race = factor(da$race, levels = c("White", "Hispanic", "Black", "Asian/NHPIs", "Other")) #white is the reference
da$insurance = factor(da$insurance, levels = c("Yes", "No")) #"Yes" is the reference group
da$siblingU18 = factor(da$siblingU18, levels = c("Yes", "No"))
da$fatherInHH = factor(da$fatherInHH)
da$motherInHH = factor(da$motherInHH)
da$parentInv = factor(da$parentInv)
da$schoolExp = factor(da$schoolExp, levels = c("good school experiences", "bad school experiences"))
(n = dim(da)[1])
set.seed(2024)
index = sample(1:n, 4500) #75% of training and 25% of test data
train = da[index,]
test = da[-index,]
dim(train)
dim(test)
(sapply(da, class))
unique(da$gender); length(unique(da$gender))
unique(da$age); length(unique(da$age))
unique(da$race); length(unique(da$race))
unique(da$insurance); length(unique(da$insurance))
unique(da$income); length(unique(da$income))
unique(da$fatherInHH); length(unique(da$fatherInHH))
unique(da$motherInHH); length(unique(da$motherInHH))
unique(da$siblingU18); length(unique(da$siblingU18))
unique(da$parentInv); length(unique(da$parentInv))
unique(da$schoolExp); length(unique(da$schoolExp))
#Chi Square test
chi_square_results = data.frame(Column = character(), P_Value = numeric(), row.names = NULL)
columns = c("year", "gender", "age", "race", "insurance", "income",
"fatherInHH", "motherInHH", "siblingU18", "parentInv", "schoolExp")
for (col in columns) {
chi_square_result <- chisq.test(table(da$mdeSI, da[, col]))
p_value <- chi_square_result$p.value
chi_square_results <- rbind(chi_square_results, data.frame(Column = col, P_Value = p_value))
}
View(chi_square_results)
chi_square_result <- round(chisq.test(table(da$mdeSI, da[, col])),4)
for (col in columns) {
chi_square_result <- chisq.test(table(da$mdeSI, da[, col]))
p_value <- round(chi_square_result$p.value,4)
chi_square_results <- rbind(chi_square_results, data.frame(Column = col, P_Value = p_value))
}
View(chi_square_results)
#Chi Square test
chi_square_results = data.frame(Column = character(), P_Value = numeric(), row.names = NULL)
columns = c("year", "gender", "age", "race", "insurance", "income",
"fatherInHH", "motherInHH", "siblingU18", "parentInv", "schoolExp")
for (col in columns) {
chi_square_result = chisq.test(table(da$mdeSI, da[, col]))
p_value = round(chi_square_result$p.value,4)
chi_square_results = rbind(chi_square_results, data.frame(Column = col, P_Value = p_value))
}
View(chi_square_results)
da2 = da
da2$mdeSI <- ifelse(da2$mdeSI == "Yes", 1, 0)
da2$gender = as.numeric(unclass(da2$gender))
da2$age = as.numeric(unclass(da2$age))
da2$race = as.numeric(unclass(da2$race))
da2$insurance = as.numeric(unclass(da2$insurance))
da2$income = as.numeric(unclass(da2$income))
da2$fatherInHH = as.numeric(unclass(da2$fatherInHH))
da2$motherInHH = as.numeric(unclass(da2$motherInHH))
da2$siblingU18 = as.numeric(unclass(da2$siblingU18))
da2$parentInv = as.numeric(unclass(da2$parentInv))
da2$schoolExp = as.numeric(unclass(da2$schoolExp))
(n2 = dim(da2)[1])
set.seed(2024)
index2 = sample(1:n2, 4500) #75% of training and 25% of test data
train2 = da2[index2,]
test2 = da2[-index2,]
dim(train2)
dim(test2)
mcor = round(cor(da2),2) #Finding pair wise correlation
corrplot(mcor, type = "lower")
#we can see that there is a similar distribution of mdeSI (Yes/No) across both categories of insurance (Yes/No)
#Thus we can say that insurance is not playing a major role towards the target variable mdeSI.
####(A) Classifier one - Logistic Classifier####
model1 = glm(mdeSI ~ year + gender + age + income + fatherInHH + siblingU18 + parentInv + schoolExp, family = binomial(logit),
data = train)
summary(model1)
anova(model1)
prob01 = predict(model1, test, type = "response")
pred01 = rep(0, 1500)
pred01[prob01 > 0.5] = 1
(CM01 = table(test$mdeSI, pred01)) #confusion matrix
(accuracy01 = (CM01[1,1] + CM01[2,2])/1500)
(recall01 = CM01[2,2]/sum(CM01[2,]))
(precision01 = CM01[2,2]/sum(CM01[,2]))
####(B) Classifier two - Random Forest####
rf = randomForest(mdeSI ~ year + gender + age + income + parentInv + schoolExp, data = train, ntree = 500)
rf_preds <- predict(rf, test)
(rf_table = table(rf_preds, test$mdeSI))
(rf_accuracy = sum(diag(rf_table))/sum(rf_table))
(rf_recall = rf_table[2,2]/sum(rf_table[2,]))
541/(541+193)
(rf_recall = rf_table[2,2]/sum(rf_table[,2]))
(CM01 = table(test$mdeSI, pred01)) #confusion matrix
543/(543+71)
(CM01 = table(pred01,test$mdeSI)) #confusion matrix
(accuracy01 = (CM01[1,1] + CM01[2,2])/1500)
(recall01 = CM01[2,2]/sum(CM01[,2]))
#Training model
model1 = glm(mdeSI ~ year + gender + age + income + fatherInHH + siblingU18 + parentInv + schoolExp, family = binomial(logit),
data = train)
prob01 = predict(model1, train, type = "response")
pred01 = rep(0, 1500)
pred01[prob01 > 0.5] = 1
(CM01 = table(pred01,train$mdeSI)) #confusion matrix
(accuracy01 = (CM01[1,1] + CM01[2,2])/4500)
(recall01 = CM01[2,2]/sum(CM01[,2]))
(precision01 = CM01[2,2]/sum(CM01[,2]))
(precision01 = CM01[2,2]/sum(CM01[2,]))
#Training model
model1 = glm(mdeSI ~ year + gender + age + income + fatherInHH + siblingU18 + parentInv + schoolExp, family = binomial(logit),
data = train)
prob01 = predict(model1, train, type = "response")
pred01 = rep(0, 4500)
pred01[prob01 > 0.5] = 1
(CM01 = table(pred01,train$mdeSI)) #confusion matrix
(accuracy01 = (CM01[1,1] + CM01[2,2])/4500)
(recall01 = CM01[2,2]/sum(CM01[,2]))
(precision01 = CM01[2,2]/sum(CM01[2,]))
#Testing Model
model1.test = glm(mdeSI ~ year + gender + age + income + fatherInHH + siblingU18 + parentInv + schoolExp, family = binomial(logit),
data = test)
prob01.test = predict(model1.test, test, type = "response")
pred01.test = rep(0, 1500)
pred01.test[prob01.test > 0.5] = 1
(CM01.test = table(pred01.test,test$mdeSI)) #confusion matrix
(accuracy01.test = (CM01.test[1,1] + CM01.test[2,2])/1500)
(recall01.test = CM01.test[2,2]/sum(CM01.test[,2]))
(precision01.test = CM01.test[2,2]/sum(CM01.test[,2]))
#Now we will plot accuracy and recall of both training and testing data
accuracy_recall = data.frame(Model = c("Training", "Testing"),
Accuracy = c(accuracy01, accuracy01.test),
Recall = c(recall01, recall01.test))
ggplot(accuracy_recall, aes(x = Model, y = value, fill = variable)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplot(accuracy_recall, aes(x = Model)) +
geom_col(aes(y = Accuracy, fill = "Accuracy"), position = position_dodge(width = 0.8)) +
geom_col(aes(y = Recall, fill = "Recall"), position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplot(accuracy_recall, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplot(accuracy_recall, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
accuracy_recall_plot <- ggplot(accuracy_recall, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplot(accuracy_recall, aes(x = Model, y = value, fill = variable)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplot(accuracy_recall, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
acc_rec_plot = ggplot(accuracy_recall, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplotly(acc_rec_plot)
install.packages("pROC")
library(pROC)
#ROC plot
roc_train = roc(train$mdeSI, prob01)
roc_test = roc(test$mdeSI, prob01.test)
ggplot() +
geom_roc(data = roc_curve_train, aes(color = "Training")) +
geom_roc(data = roc_curve_test, aes(color = "Testing")) +
labs(title = "ROC Curve for Training and Testing Models",
x = "False Positive Rate", y = "True Positive Rate", color = "Model") +
theme_minimal()
ggplot() +
geom_roc(data = roc_train, aes(color = "Training")) +
geom_roc(data = roc_test, aes(color = "Testing")) +
labs(title = "ROC Curve for Training and Testing Models",
x = "False Positive Rate", y = "True Positive Rate", color = "Model") +
theme_minimal()
plot_ROC(roc_train, col = "blue", main = "ROC Curve for Training and Testing Models")
ggroc(roc_train, col = "blue", linetype = "solid") +
ggroc(roc_test, col = "red", linetype = "dashed") +
labs(title = "ROC Curve for Training and Testing Models",
x = "False Positive Rate",
y = "True Positive Rate",
color = "Model") +
theme_minimal()
ggplot() +
geom_roc(roc_train, label = "Training Data", color = "blue") +
geom_roc(roc_test, label = "Testing Data", color = "red") +
labs(title = "ROC Curve - Model Performance",
x = "False Positive Rate (FPR)",
y = "True Positive Rate (TPR)") +
scale_x_continuous(limits = c(0, 1), labels = scales::percent) +
scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
diag_line(color = "gray", linetype = "dashed") +
theme_classic() +
theme(legend.title = element_text(size = 12))
library(pROC)
ggplot() +
geom_roc(roc_train, label = "Training Data", color = "blue") +
geom_roc(roc_test, label = "Testing Data", color = "red") +
labs(title = "ROC Curve - Model Performance",
x = "False Positive Rate (FPR)",
y = "True Positive Rate (TPR)") +
scale_x_continuous(limits = c(0, 1), labels = scales::percent) +
scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
diag_line(color = "gray", linetype = "dashed") +
theme_classic() +
theme(legend.title = element_text(size = 12))
plot(roc_train)
lines(roc_test, color="green")
install.packages("plotROC")
library(plotROC)
ggroc(roc_train) +
labs(title = "ROC Curve for Training Model",
x = "False Positive Rate",
y = "True Positive Rate")
ggplot() +
geom_roc(data = roc_train, aes(color = "ROC Curve")) +
labs(title = "ROC Curve for Training Model",
x = "False Positive Rate",
y = "True Positive Rate",
color = "Model") +
theme_minimal()
#ROC plot
roc_train = roc(train$mdeSI, prob01)
ggplot() +
geom_roc(data = roc_train, aes(color = "ROC Curve")) +
labs(title = "ROC Curve for Training Model",
x = "False Positive Rate",
y = "True Positive Rate",
color = "Model") +
theme_minimal()
#ROC plot
roc_data_train <- data.frame(response = train$mdeSI, predicted_prob = prob01)
roc_train = roc(roc_data_train$response, roc_data_train$predicted_prob)
ggplot() +
geom_roc(data = roc_train, aes(color = "ROC Curve")) +
labs(title = "ROC Curve for Training Model",
x = "False Positive Rate",
y = "True Positive Rate",
color = "Model") +
theme_minimal()
plot_ROC(roc_train, col = "blue", main = "ROC Curve for Training and Testing Models")
library(pROC)
plot_ROC(roc_train, col = "blue", main = "ROC Curve for Training and Testing Models")
# Add ROC curve for testing data
lines(roc_test, col = "green")
plot(roc_train)
lines(roc_test, color="green")
lines(roc_test, col = "green")
plot(roc_train, col = "red")
lines(roc_test, col = "green")
plot(roc_train, col = "blue", main = "ROC Curve for Training and Testing Models")
lines(roc_test, col = "green")
legend("bottomright", legend = c("Training", "Testing"), col = c("blue", "green"), lty = 1)
(auc_train = auc(roc_train))
(auc_test = auc(roc_test))
#Accuracy and recall plot
accuracy_recall_rf = data.frame(Model = c("Training", "Testing"),
Accuracy = c(rf_accuracy, rf_accuracy.test),
Recall = c(rf_recall, rf_recall.test))
#Training model
rf = randomForest(mdeSI ~ year + gender + age + income + parentInv + schoolExp, data = train, ntree = 500)
rf_preds <- predict(rf, train)
(rf_table = table(rf_preds, train$mdeSI))
(rf_accuracy = sum(diag(rf_table))/sum(rf_table))
(rf_recall = rf_table[2,2]/sum(rf_table[,2]))
#Testing Model
rf.test = randomForest(mdeSI ~ year + gender + age + income + parentInv + schoolExp, data = test, ntree = 500)
rf_preds.test <- predict(rf, test)
(rf_table.test = table(rf_preds.test, test$mdeSI))
(rf_accuracy.test = sum(diag(rf_table.test))/sum(rf_table.test))
(rf_recall.test = rf_table.test[2,2]/sum(rf_table.test[,2]))
#Accuracy and recall plot
accuracy_recall_rf = data.frame(Model = c("Training", "Testing"),
Accuracy = c(rf_accuracy, rf_accuracy.test),
Recall = c(rf_recall, rf_recall.test))
acc_rec_plot_rf = ggplot(accuracy_recall_rf, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplotly(acc_rec_plot_rf)
#AUC Value and ROC plot
roc_train_rf = roc(train$mdeSI, rf_preds, levels = c("No", "Yes"))
#AUC Value and ROC plot
rf_probs_train = predict(rf, train, type = "prob")[, "Yes"]
roc_train_rf = roc(train$mdeSI, rf_probs_train, levels = c("No", "Yes"))
(auc_train = auc(roc_train_rf))
rf_probs_test = predict(rf.test, test, type = "prob")[, "Yes"]
roc_test_rf = roc(test$mdeSI, rf_probs_test, levels = c("No", "Yes"))
(auc_test = auc(roc_test_rf))
plot(roc_train, col = "red", main = "ROC Curve for Training and Testing Models")
lines(roc_test, col = "purple")
legend("bottomright", legend = c("Training", "Testing"), col = c("red", "purple"), lty = 1)
library(corrplot)
library(ggplot2)
library(treemap)
library(tidyr)
library(MASS)
library(mixlm)
library(randomForest)
library(RColorBrewer)
library(plotly)
library(pROC)
da = read.csv("depression.csv", header = T)
dim(da) #6,000 by 12
str(da)
da$mdeSI = factor(da$mdeSI)
da$income = factor(da$income)
da$gender = factor(da$gender, levels = c("Male", "Female")) #Male is the reference group
da$age = factor(da$age)
da$race = factor(da$race, levels = c("White", "Hispanic", "Black", "Asian/NHPIs", "Other")) #white is the reference
da$insurance = factor(da$insurance, levels = c("Yes", "No")) #"Yes" is the reference group
da$siblingU18 = factor(da$siblingU18, levels = c("Yes", "No"))
da$fatherInHH = factor(da$fatherInHH)
da$motherInHH = factor(da$motherInHH)
da$parentInv = factor(da$parentInv)
da$schoolExp = factor(da$schoolExp, levels = c("good school experiences", "bad school experiences"))
(n = dim(da)[1])
set.seed(2024)
index = sample(1:n, 4500) #75% of training and 25% of test data
train = da[index,]
test = da[-index,]
dim(train)
dim(test)
#Training model
model1 = glm(mdeSI ~ year + gender + age + income + fatherInHH + siblingU18 + parentInv + schoolExp, family = binomial(logit),
data = train)
prob01 = predict(model1, train, type = "response")
pred01 = rep(0, 4500)
pred01[prob01 > 0.5] = 1
(CM01 = table(pred01,train$mdeSI)) #confusion matrix
(accuracy01 = (CM01[1,1] + CM01[2,2])/4500)
(recall01 = CM01[2,2]/sum(CM01[,2]))
(precision01 = CM01[2,2]/sum(CM01[2,]))
#Testing Model
model1.test = glm(mdeSI ~ year + gender + age + income + fatherInHH + siblingU18 + parentInv + schoolExp, family = binomial(logit),
data = test)
prob01.test = predict(model1.test, test, type = "response")
pred01.test = rep(0, 1500)
pred01.test[prob01.test > 0.5] = 1
(CM01.test = table(pred01.test,test$mdeSI)) #confusion matrix
(accuracy01.test = (CM01.test[1,1] + CM01.test[2,2])/1500)
(recall01.test = CM01.test[2,2]/sum(CM01.test[,2]))
(precision01.test = CM01.test[2,2]/sum(CM01.test[,2]))
#Now we will plot accuracy and recall of both training and testing data
accuracy_recall = data.frame(Model = c("Training", "Testing"),
Accuracy = c(accuracy01, accuracy01.test),
Recall = c(recall01, recall01.test))
acc_rec_plot = ggplot(accuracy_recall, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplotly(acc_rec_plot)
#AUC value and ROC plot
roc_train = roc(train$mdeSI, prob01, levels = c("No", "Yes"))
(auc_train = auc(roc_train))
roc_test = roc(test$mdeSI, prob01.test, levels = c("No", "Yes"))
(auc_test = auc(roc_test))
plot(roc_train, col = "blue", main = "ROC Curve for Training and Testing Models")
lines(roc_test, col = "green")
legend("bottomright", legend = c("Training", "Testing"), col = c("blue", "green"), lty = 1)
plot(roc_train, col = "blue", main = "ROC Curve for Training and Testing Models")
lines(roc_test, col = "green")
legend("bottomright", legend = c("Train", "Test"), col = c("blue", "green"), lty = 1)
#Training model
rf = randomForest(mdeSI ~ year + gender + age + income + parentInv + schoolExp, data = train, ntree = 500)
rf_preds <- predict(rf, train)
(rf_table = table(rf_preds, train$mdeSI))
(rf_accuracy = sum(diag(rf_table))/sum(rf_table))
(rf_recall = rf_table[2,2]/sum(rf_table[,2]))
#Testing Model
rf.test = randomForest(mdeSI ~ year + gender + age + income + parentInv + schoolExp, data = test, ntree = 500)
rf_preds.test <- predict(rf, test)
(rf_table.test = table(rf_preds.test, test$mdeSI))
(rf_accuracy.test = sum(diag(rf_table.test))/sum(rf_table.test))
(rf_recall.test = rf_table.test[2,2]/sum(rf_table.test[,2]))
#Accuracy and recall plot
accuracy_recall_rf = data.frame(Model = c("Training", "Testing"),
Accuracy = c(rf_accuracy, rf_accuracy.test),
Recall = c(rf_recall, rf_recall.test))
acc_rec_plot_rf = ggplot(accuracy_recall_rf, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Training and Testing Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplotly(acc_rec_plot_rf)
acc_rec_plot_rf = ggplot(accuracy_recall_rf, aes(x = Model)) +
geom_bar(aes(y = Accuracy, fill = "Accuracy"), stat = "identity", position = position_dodge(width = 0.8)) +
geom_bar(aes(y = Recall, fill = "Recall"), stat = "identity", position = position_dodge(width = 0.8)) +
labs(title = "Accuracy and Recall of Train and Test Models",
x = "Model", y = "Value", fill = "Metric") +
theme_minimal()
ggplotly(acc_rec_plot_rf)
#AUC Value and ROC plot
rf_probs_train = predict(rf, train, type = "prob")[, "Yes"]
rf_probs_test = predict(rf.test, test, type = "prob")[, "Yes"]
roc_train_rf = roc(train$mdeSI, rf_probs_train, levels = c("No", "Yes"))
(auc_train = auc(roc_train_rf))
roc_test_rf = roc(test$mdeSI, rf_probs_test, levels = c("No", "Yes"))
(auc_test = auc(roc_test_rf))
plot(roc_train, col = "red", main = "ROC Curve for Training and Testing Models")
lines(roc_test, col = "purple")
legend("bottomright", legend = c("Training", "Testing"), col = c("red", "purple"), lty = 1)
plot(roc_train, col = "red", main = "ROC Curve for Train and Test Models")
lines(roc_test, col = "purple")
legend("bottomright", legend = c("Training", "Testing"), col = c("red", "purple"), lty = 1)
plot(roc_train, col = "red", main = "ROC Curve for Train and Test Models")
lines(roc_test, col = "purple")
legend("bottomright", legend = c("Train", "Test"), col = c("red", "purple"), lty = 1)
